{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "C13PSHeK94Bd",
        "outputId": "0e8e8b8f-e744-404b-fb05-5aefbd794d66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Fine-Tuning Dynamic-Gating ResNet50 on TF Flowers ---\n",
            "Epoch 1/3\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2094s\u001b[0m 25s/step - accuracy: 0.6939 - loss: 0.7910 - val_accuracy: 0.8711 - val_loss: 0.4717\n",
            "Epoch 2/3\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2012s\u001b[0m 25s/step - accuracy: 0.9799 - loss: 0.0783 - val_accuracy: 0.9238 - val_loss: 0.2572\n",
            "Epoch 3/3\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2024s\u001b[0m 24s/step - accuracy: 0.9973 - loss: 0.0151 - val_accuracy: 0.9383 - val_loss: 0.1988\n",
            "\n",
            "--- Fine-Tuning Dynamic-Gating EfficientNetB0 on TF Flowers ---\n",
            "Epoch 1/3\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m831s\u001b[0m 10s/step - accuracy: 0.5191 - loss: 1.2658 - val_accuracy: 0.9111 - val_loss: 0.3374\n",
            "Epoch 2/3\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m797s\u001b[0m 10s/step - accuracy: 0.9060 - loss: 0.3725 - val_accuracy: 0.9474 - val_loss: 0.1935\n",
            "Epoch 3/3\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m816s\u001b[0m 10s/step - accuracy: 0.9600 - loss: 0.1758 - val_accuracy: 0.9510 - val_loss: 0.1619\n",
            "ResNet50 Final Accuracy: 0.9600\n",
            "EfficientNetB0 Final Accuracy: 0.9345\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import ResNet50, EfficientNetB0, resnet50, efficientnet\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# 1. Load the TF Flowers Dataset\n",
        "# ---------------------------------------------------\n",
        "# Create train/validation/test split\n",
        "(dataset_train, dataset_val, dataset_test), info = tfds.load(\n",
        "    'tf_flowers',\n",
        "    split=['train[:70%]', 'train[70%:85%]', 'train[85%:]'],\n",
        "    as_supervised=True,\n",
        "    with_info=True\n",
        ")\n",
        "\n",
        "# Number of classes in TF Flowers\n",
        "num_classes = info.features['label'].num_classes\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# 2. Preprocess Data for ResNet and EfficientNet\n",
        "# ---------------------------------------------------\n",
        "IMG_SIZE = 224\n",
        "batch_size = 32\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "def preprocess_resnet(image, label):\n",
        "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "    image = resnet50.preprocess_input(image)\n",
        "    return image, tf.one_hot(label, num_classes)\n",
        "\n",
        "def preprocess_efficientnet(image, label):\n",
        "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "    image = efficientnet.preprocess_input(image)\n",
        "    return image, tf.one_hot(label, num_classes)\n",
        "\n",
        "# Create tf.data pipelines\n",
        "train_ds_resnet = (dataset_train\n",
        "                   .map(preprocess_resnet, num_parallel_calls=AUTOTUNE)\n",
        "                   .batch(batch_size)\n",
        "                   .prefetch(AUTOTUNE))\n",
        "\n",
        "val_ds_resnet = (dataset_val\n",
        "                 .map(preprocess_resnet, num_parallel_calls=AUTOTUNE)\n",
        "                 .batch(batch_size)\n",
        "                 .prefetch(AUTOTUNE))\n",
        "\n",
        "test_ds_resnet = (dataset_test\n",
        "                  .map(preprocess_resnet, num_parallel_calls=AUTOTUNE)\n",
        "                  .batch(batch_size)\n",
        "                  .prefetch(AUTOTUNE))\n",
        "\n",
        "train_ds_eff = (dataset_train\n",
        "                .map(preprocess_efficientnet, num_parallel_calls=AUTOTUNE)\n",
        "                .batch(batch_size)\n",
        "                .prefetch(AUTOTUNE))\n",
        "\n",
        "val_ds_eff = (dataset_val\n",
        "              .map(preprocess_efficientnet, num_parallel_calls=AUTOTUNE)\n",
        "              .batch(batch_size)\n",
        "              .prefetch(AUTOTUNE))\n",
        "\n",
        "test_ds_eff = (dataset_test\n",
        "               .map(preprocess_efficientnet, num_parallel_calls=AUTOTUNE)\n",
        "               .batch(batch_size)\n",
        "               .prefetch(AUTOTUNE))\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# 3. Define Dynamic Channel Gate Layer\n",
        "# ---------------------------------------------------\n",
        "class DynamicChannelGate(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_channels, name=None):\n",
        "        super().__init__(name=name)\n",
        "        self.gate_params = tf.Variable(\n",
        "            initial_value=tf.ones((num_channels,), dtype=tf.float32),\n",
        "            trainable=True,\n",
        "            name=\"gate_params\"\n",
        "        )\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        gate = tf.sigmoid(self.gate_params)\n",
        "        gate = tf.reshape(gate, (1, 1, 1, -1))\n",
        "        return inputs * gate\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# 4. Define ResNet50 Model with Dynamic Gating\n",
        "# ---------------------------------------------------\n",
        "def create_resnet_dynamic_gating(input_shape, num_classes):\n",
        "    base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
        "    base_model.trainable = True\n",
        "\n",
        "    x = base_model.output\n",
        "    num_channels = x.shape[-1]\n",
        "    gating_layer = DynamicChannelGate(num_channels=num_channels, name=\"dynamic_gating\")\n",
        "    x = gating_layer(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    model = models.Model(inputs=base_model.input, outputs=outputs, name=\"ResNet_DynamicGating\")\n",
        "    return model\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# 5. Define EfficientNetB0 Model with Dynamic Gating\n",
        "# ---------------------------------------------------\n",
        "def create_efficientnet_dynamic_gating(input_shape, num_classes):\n",
        "    base_model = EfficientNetB0(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
        "    base_model.trainable = True\n",
        "\n",
        "    x = base_model.output\n",
        "    num_channels = x.shape[-1]\n",
        "    gating_layer = DynamicChannelGate(num_channels=num_channels, name=\"dynamic_gating\")\n",
        "    x = gating_layer(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    model = models.Model(inputs=base_model.input, outputs=outputs, name=\"EfficientNet_DynamicGating\")\n",
        "    return model\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# 6. Compile and Train the Models\n",
        "# ---------------------------------------------------\n",
        "# ResNet50 Model\n",
        "resnet_model = create_resnet_dynamic_gating((IMG_SIZE, IMG_SIZE, 3), num_classes)\n",
        "resnet_model.compile(optimizer=Adam(learning_rate=1e-4), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "print(\"\\n--- Fine-Tuning Dynamic-Gating ResNet50 on TF Flowers ---\")\n",
        "history_resnet = resnet_model.fit(train_ds_resnet, epochs=3, validation_data=val_ds_resnet, verbose=1)\n",
        "\n",
        "# EfficientNetB0 Model\n",
        "eff_model = create_efficientnet_dynamic_gating((IMG_SIZE, IMG_SIZE, 3), num_classes)\n",
        "eff_model.compile(optimizer=Adam(learning_rate=1e-4), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "print(\"\\n--- Fine-Tuning Dynamic-Gating EfficientNetB0 on TF Flowers ---\")\n",
        "history_eff = eff_model.fit(train_ds_eff, epochs=3, validation_data=val_ds_eff, verbose=1)\n",
        "\n",
        "# Evaluate ResNet50\n",
        "loss_resnet, acc_resnet = resnet_model.evaluate(test_ds_resnet, verbose=0)\n",
        "print(f\"ResNet50 Final Accuracy: {acc_resnet:.4f}\")\n",
        "\n",
        "# Evaluate EfficientNetB0\n",
        "loss_eff, acc_eff = eff_model.evaluate(test_ds_eff, verbose=0)\n",
        "print(f\"EfficientNetB0 Final Accuracy: {acc_eff:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}