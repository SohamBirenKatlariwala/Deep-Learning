{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv, BatchNorm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "\n",
        "# Check device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load TF-Flowers dataset\n",
        "ds_train = tfds.load('tf_flowers', split='train', as_supervised=True)\n",
        "\n",
        "# Convert to PyTorch Dataset\n",
        "class FlowersDataset(Dataset):\n",
        "    def __init__(self, tf_dataset, transform=None):\n",
        "        self.data = list(tf_dataset)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, label = self.data[idx]\n",
        "        img = img.numpy()\n",
        "        img = transforms.ToPILImage()(img)\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label.numpy()\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "flowers_dataset = FlowersDataset(ds_train, transform=transform)\n",
        "dataloader = DataLoader(flowers_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Fine-tune ResNet101\n",
        "resnet = models.resnet101(pretrained=True)\n",
        "resnet.fc = nn.Linear(resnet.fc.in_features, 5)\n",
        "resnet.to(device)\n",
        "optimizer = optim.Adam(resnet.parameters(), lr=0.0005)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def train_resnet(model, dataloader, optimizer, criterion, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss, correct = 0, 0\n",
        "        for img, label in dataloader:\n",
        "            img, label = img.to(device), label.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(img)\n",
        "            loss = criterion(output, label)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            correct += (output.argmax(dim=1) == label).sum().item()\n",
        "        accuracy = correct / len(flowers_dataset)\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(dataloader):.4f}, Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Final ResNet Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "train_resnet(resnet, dataloader, optimizer, criterion, epochs=10)\n",
        "\n",
        "# Feature extraction\n",
        "resnet.fc = nn.Identity()\n",
        "def extract_features(dataset, model):\n",
        "    model.eval()\n",
        "    features, labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for img, label in dataset:\n",
        "            img = img.unsqueeze(0).to(device)\n",
        "            feat = model(img).cpu().numpy().flatten()\n",
        "            features.append(feat)\n",
        "            labels.append(label)\n",
        "    return np.array(features), np.array(labels)\n",
        "\n",
        "features, labels = extract_features(flowers_dataset, resnet)\n",
        "labels = LabelEncoder().fit_transform(labels)\n",
        "\n",
        "# Build optimized KNN graph\n",
        "def build_knn_graph(features, k=15):\n",
        "    adj_matrix = kneighbors_graph(features, k, mode='connectivity', include_self=True).toarray()\n",
        "    edge_index = np.array(np.nonzero(adj_matrix))\n",
        "    return torch.tensor(edge_index, dtype=torch.long)\n",
        "\n",
        "edge_index = build_knn_graph(features)\n",
        "\n",
        "graph_data = Data(\n",
        "    x=torch.tensor(features, dtype=torch.float),\n",
        "    edge_index=edge_index,\n",
        "    y=torch.tensor(labels, dtype=torch.long)\n",
        ")\n",
        "\n",
        "# Define Enhanced GCN\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.bn1 = BatchNorm(hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.bn2 = BatchNorm(hidden_channels)\n",
        "        self.conv3 = GCNConv(hidden_channels, out_channels)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        x = self.bn1(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv2(x, edge_index).relu()\n",
        "        x = self.bn2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv3(x, edge_index)\n",
        "        return x\n",
        "\n",
        "# Initialize & Train GCN\n",
        "gcn = GCN(in_channels=features.shape[1], hidden_channels=512, out_channels=len(set(labels))).to(device)\n",
        "optimizer = optim.Adam(gcn.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def train_gcn(model, data, optimizer, loss_fn, scheduler, epochs=100):\n",
        "    model.train()\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data.x.to(device), data.edge_index.to(device))\n",
        "        loss = loss_fn(out, data.y.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        acc = (out.argmax(dim=1) == data.y.to(device)).float().mean().item()\n",
        "        best_acc = max(best_acc, acc)\n",
        "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}, Accuracy: {acc:.4f}\")\n",
        "    print(f\"Final GCN Accuracy: {best_acc:.4f}\")\n",
        "\n",
        "train_gcn(gcn, graph_data, optimizer, loss_fn, scheduler, epochs=100)\n",
        "\n",
        "print(\"Training complete. Best accuracy achieved during training is displayed above.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAffuQlca2x0",
        "outputId": "fc623c53-feb3-4810-e267-fab2b1a83b4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.6416, Accuracy: 0.7777\n",
            "Epoch 2, Loss: 0.3801, Accuracy: 0.8673\n",
            "Epoch 3, Loss: 0.2824, Accuracy: 0.9035\n",
            "Epoch 4, Loss: 0.2488, Accuracy: 0.9114\n",
            "Epoch 5, Loss: 0.1623, Accuracy: 0.9422\n",
            "Epoch 6, Loss: 0.1148, Accuracy: 0.9599\n",
            "Epoch 7, Loss: 0.1470, Accuracy: 0.9534\n",
            "Epoch 8, Loss: 0.1209, Accuracy: 0.9583\n",
            "Epoch 9, Loss: 0.1151, Accuracy: 0.9629\n",
            "Epoch 10, Loss: 0.1117, Accuracy: 0.9643\n",
            "Final ResNet Accuracy: 0.9643\n",
            "Epoch 1, Loss: 1.8806, Accuracy: 0.3245\n",
            "Epoch 2, Loss: 0.0950, Accuracy: 0.9752\n",
            "Epoch 3, Loss: 0.0724, Accuracy: 0.9796\n",
            "Epoch 4, Loss: 0.0686, Accuracy: 0.9809\n",
            "Epoch 5, Loss: 0.0611, Accuracy: 0.9807\n",
            "Epoch 6, Loss: 0.0543, Accuracy: 0.9834\n",
            "Epoch 7, Loss: 0.0508, Accuracy: 0.9831\n",
            "Epoch 8, Loss: 0.0459, Accuracy: 0.9839\n",
            "Epoch 9, Loss: 0.0466, Accuracy: 0.9864\n",
            "Epoch 10, Loss: 0.0455, Accuracy: 0.9845\n",
            "Epoch 11, Loss: 0.0400, Accuracy: 0.9875\n",
            "Epoch 12, Loss: 0.0396, Accuracy: 0.9875\n",
            "Epoch 13, Loss: 0.0410, Accuracy: 0.9886\n",
            "Epoch 14, Loss: 0.0417, Accuracy: 0.9853\n",
            "Epoch 15, Loss: 0.0381, Accuracy: 0.9877\n",
            "Epoch 16, Loss: 0.0374, Accuracy: 0.9869\n",
            "Epoch 17, Loss: 0.0390, Accuracy: 0.9877\n",
            "Epoch 18, Loss: 0.0364, Accuracy: 0.9856\n",
            "Epoch 19, Loss: 0.0371, Accuracy: 0.9886\n",
            "Epoch 20, Loss: 0.0342, Accuracy: 0.9888\n",
            "Epoch 21, Loss: 0.0364, Accuracy: 0.9872\n",
            "Epoch 22, Loss: 0.0359, Accuracy: 0.9866\n",
            "Epoch 23, Loss: 0.0376, Accuracy: 0.9872\n",
            "Epoch 24, Loss: 0.0341, Accuracy: 0.9875\n",
            "Epoch 25, Loss: 0.0373, Accuracy: 0.9877\n",
            "Epoch 26, Loss: 0.0361, Accuracy: 0.9856\n",
            "Epoch 27, Loss: 0.0341, Accuracy: 0.9886\n",
            "Epoch 28, Loss: 0.0341, Accuracy: 0.9869\n",
            "Epoch 29, Loss: 0.0354, Accuracy: 0.9866\n",
            "Epoch 30, Loss: 0.0341, Accuracy: 0.9883\n",
            "Epoch 31, Loss: 0.0364, Accuracy: 0.9872\n",
            "Epoch 32, Loss: 0.0333, Accuracy: 0.9883\n",
            "Epoch 33, Loss: 0.0324, Accuracy: 0.9883\n",
            "Epoch 34, Loss: 0.0343, Accuracy: 0.9888\n",
            "Epoch 35, Loss: 0.0348, Accuracy: 0.9866\n",
            "Epoch 36, Loss: 0.0343, Accuracy: 0.9875\n",
            "Epoch 37, Loss: 0.0345, Accuracy: 0.9866\n",
            "Epoch 38, Loss: 0.0325, Accuracy: 0.9888\n",
            "Epoch 39, Loss: 0.0323, Accuracy: 0.9891\n",
            "Epoch 40, Loss: 0.0338, Accuracy: 0.9880\n",
            "Epoch 41, Loss: 0.0347, Accuracy: 0.9869\n",
            "Epoch 42, Loss: 0.0321, Accuracy: 0.9894\n",
            "Epoch 43, Loss: 0.0342, Accuracy: 0.9866\n",
            "Epoch 44, Loss: 0.0318, Accuracy: 0.9899\n",
            "Epoch 45, Loss: 0.0346, Accuracy: 0.9872\n",
            "Epoch 46, Loss: 0.0332, Accuracy: 0.9864\n",
            "Epoch 47, Loss: 0.0322, Accuracy: 0.9880\n",
            "Epoch 48, Loss: 0.0331, Accuracy: 0.9891\n",
            "Epoch 49, Loss: 0.0342, Accuracy: 0.9869\n",
            "Epoch 50, Loss: 0.0330, Accuracy: 0.9875\n",
            "Epoch 51, Loss: 0.0342, Accuracy: 0.9880\n",
            "Epoch 52, Loss: 0.0342, Accuracy: 0.9872\n",
            "Epoch 53, Loss: 0.0338, Accuracy: 0.9875\n",
            "Epoch 54, Loss: 0.0343, Accuracy: 0.9866\n",
            "Epoch 55, Loss: 0.0338, Accuracy: 0.9869\n",
            "Epoch 56, Loss: 0.0317, Accuracy: 0.9877\n",
            "Epoch 57, Loss: 0.0355, Accuracy: 0.9869\n",
            "Epoch 58, Loss: 0.0352, Accuracy: 0.9869\n",
            "Epoch 59, Loss: 0.0339, Accuracy: 0.9877\n",
            "Epoch 60, Loss: 0.0339, Accuracy: 0.9877\n",
            "Epoch 61, Loss: 0.0328, Accuracy: 0.9886\n",
            "Epoch 62, Loss: 0.0321, Accuracy: 0.9888\n",
            "Epoch 63, Loss: 0.0330, Accuracy: 0.9894\n",
            "Epoch 64, Loss: 0.0335, Accuracy: 0.9886\n",
            "Epoch 65, Loss: 0.0337, Accuracy: 0.9883\n",
            "Epoch 66, Loss: 0.0349, Accuracy: 0.9883\n",
            "Epoch 67, Loss: 0.0325, Accuracy: 0.9891\n",
            "Epoch 68, Loss: 0.0327, Accuracy: 0.9880\n",
            "Epoch 69, Loss: 0.0336, Accuracy: 0.9886\n",
            "Epoch 70, Loss: 0.0316, Accuracy: 0.9899\n",
            "Epoch 71, Loss: 0.0320, Accuracy: 0.9886\n",
            "Epoch 72, Loss: 0.0326, Accuracy: 0.9875\n",
            "Epoch 73, Loss: 0.0320, Accuracy: 0.9880\n",
            "Epoch 74, Loss: 0.0338, Accuracy: 0.9877\n",
            "Epoch 75, Loss: 0.0311, Accuracy: 0.9888\n",
            "Epoch 76, Loss: 0.0324, Accuracy: 0.9877\n",
            "Epoch 77, Loss: 0.0322, Accuracy: 0.9888\n",
            "Epoch 78, Loss: 0.0294, Accuracy: 0.9888\n",
            "Epoch 79, Loss: 0.0304, Accuracy: 0.9894\n",
            "Epoch 80, Loss: 0.0314, Accuracy: 0.9886\n",
            "Epoch 81, Loss: 0.0306, Accuracy: 0.9886\n",
            "Epoch 82, Loss: 0.0305, Accuracy: 0.9880\n",
            "Epoch 83, Loss: 0.0314, Accuracy: 0.9880\n",
            "Epoch 84, Loss: 0.0310, Accuracy: 0.9886\n",
            "Epoch 85, Loss: 0.0318, Accuracy: 0.9875\n",
            "Epoch 86, Loss: 0.0322, Accuracy: 0.9872\n",
            "Epoch 87, Loss: 0.0313, Accuracy: 0.9877\n",
            "Epoch 88, Loss: 0.0318, Accuracy: 0.9875\n",
            "Epoch 89, Loss: 0.0301, Accuracy: 0.9883\n",
            "Epoch 90, Loss: 0.0318, Accuracy: 0.9886\n",
            "Epoch 91, Loss: 0.0300, Accuracy: 0.9883\n",
            "Epoch 92, Loss: 0.0285, Accuracy: 0.9894\n",
            "Epoch 93, Loss: 0.0301, Accuracy: 0.9888\n",
            "Epoch 94, Loss: 0.0299, Accuracy: 0.9894\n",
            "Epoch 95, Loss: 0.0309, Accuracy: 0.9877\n",
            "Epoch 96, Loss: 0.0299, Accuracy: 0.9894\n",
            "Epoch 97, Loss: 0.0284, Accuracy: 0.9894\n",
            "Epoch 98, Loss: 0.0294, Accuracy: 0.9886\n",
            "Epoch 99, Loss: 0.0287, Accuracy: 0.9907\n",
            "Epoch 100, Loss: 0.0300, Accuracy: 0.9905\n",
            "Final GCN Accuracy: 0.9907\n",
            "Training complete. Best accuracy achieved during training is displayed above.\n"
          ]
        }
      ]
    }
  ]
}