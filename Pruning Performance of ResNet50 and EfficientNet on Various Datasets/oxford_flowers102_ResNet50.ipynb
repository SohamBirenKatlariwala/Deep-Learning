{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0IvPk-HoqYd",
        "outputId": "eaf1ce94-e8a7-4fc8-e35e-4038174de186"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Fine-Tuning ResNet50 on oxford_flowers102 ---\n",
            "Epoch 1/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 721ms/step - accuracy: 0.0059 - loss: 5.5271 - val_accuracy: 0.0245 - val_loss: 4.8869\n",
            "Epoch 2/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 121ms/step - accuracy: 0.0371 - loss: 4.9157 - val_accuracy: 0.0392 - val_loss: 4.5852\n",
            "Epoch 3/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 144ms/step - accuracy: 0.0504 - loss: 4.5453 - val_accuracy: 0.0588 - val_loss: 4.3382\n",
            "Epoch 4/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - accuracy: 0.0888 - loss: 4.1710 - val_accuracy: 0.0882 - val_loss: 4.1096\n",
            "Epoch 5/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 146ms/step - accuracy: 0.1084 - loss: 3.8883 - val_accuracy: 0.1275 - val_loss: 3.8978\n",
            "Epoch 6/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 121ms/step - accuracy: 0.1658 - loss: 3.5211 - val_accuracy: 0.1863 - val_loss: 3.7035\n",
            "Epoch 7/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 146ms/step - accuracy: 0.2436 - loss: 3.3270 - val_accuracy: 0.2157 - val_loss: 3.5191\n",
            "Epoch 8/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - accuracy: 0.3172 - loss: 3.0307 - val_accuracy: 0.2843 - val_loss: 3.3450\n",
            "Epoch 9/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - accuracy: 0.3820 - loss: 2.8310 - val_accuracy: 0.3480 - val_loss: 3.1843\n",
            "Epoch 10/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 122ms/step - accuracy: 0.4384 - loss: 2.6569 - val_accuracy: 0.3971 - val_loss: 3.0351\n",
            "Epoch 11/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 145ms/step - accuracy: 0.4590 - loss: 2.5057 - val_accuracy: 0.4608 - val_loss: 2.8996\n",
            "Epoch 12/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 169ms/step - accuracy: 0.5475 - loss: 2.2573 - val_accuracy: 0.4853 - val_loss: 2.7748\n",
            "Epoch 13/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - accuracy: 0.5897 - loss: 2.0866 - val_accuracy: 0.5000 - val_loss: 2.6631\n",
            "Epoch 14/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - accuracy: 0.5994 - loss: 1.9964 - val_accuracy: 0.5196 - val_loss: 2.5617\n",
            "Epoch 15/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - accuracy: 0.6888 - loss: 1.8050 - val_accuracy: 0.5392 - val_loss: 2.4622\n",
            "Epoch 16/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 0.7021 - loss: 1.6780 - val_accuracy: 0.5490 - val_loss: 2.3724\n",
            "Epoch 17/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 0.7781 - loss: 1.5577 - val_accuracy: 0.5637 - val_loss: 2.2930\n",
            "Epoch 18/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 184ms/step - accuracy: 0.7979 - loss: 1.4399 - val_accuracy: 0.5784 - val_loss: 2.2180\n",
            "Epoch 19/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - accuracy: 0.7958 - loss: 1.3887 - val_accuracy: 0.5882 - val_loss: 2.1494\n",
            "Epoch 20/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - accuracy: 0.8598 - loss: 1.2324 - val_accuracy: 0.6029 - val_loss: 2.0883\n",
            "Epoch 21/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 144ms/step - accuracy: 0.8413 - loss: 1.1891 - val_accuracy: 0.6176 - val_loss: 2.0374\n",
            "Epoch 22/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - accuracy: 0.8424 - loss: 1.1533 - val_accuracy: 0.6275 - val_loss: 1.9846\n",
            "Epoch 23/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - accuracy: 0.8465 - loss: 1.0872 - val_accuracy: 0.6373 - val_loss: 1.9290\n",
            "Epoch 24/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 122ms/step - accuracy: 0.8932 - loss: 0.9790 - val_accuracy: 0.6422 - val_loss: 1.8839\n",
            "Epoch 25/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 145ms/step - accuracy: 0.8830 - loss: 0.9585 - val_accuracy: 0.6471 - val_loss: 1.8456\n",
            "Epoch 26/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - accuracy: 0.8785 - loss: 0.9005 - val_accuracy: 0.6471 - val_loss: 1.8098\n",
            "Epoch 27/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 124ms/step - accuracy: 0.9229 - loss: 0.8515 - val_accuracy: 0.6569 - val_loss: 1.7739\n",
            "Epoch 28/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 0.9241 - loss: 0.8191 - val_accuracy: 0.6569 - val_loss: 1.7328\n",
            "Epoch 29/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - accuracy: 0.9169 - loss: 0.7855 - val_accuracy: 0.6569 - val_loss: 1.7008\n",
            "Epoch 30/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 0.9292 - loss: 0.7299 - val_accuracy: 0.6814 - val_loss: 1.6723\n",
            "Epoch 31/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 120ms/step - accuracy: 0.9373 - loss: 0.7014 - val_accuracy: 0.6863 - val_loss: 1.6436\n",
            "Epoch 32/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - accuracy: 0.9521 - loss: 0.6569 - val_accuracy: 0.6765 - val_loss: 1.6221\n",
            "Epoch 33/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 0.9478 - loss: 0.6198 - val_accuracy: 0.6814 - val_loss: 1.5970\n",
            "Epoch 34/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 121ms/step - accuracy: 0.9558 - loss: 0.6047 - val_accuracy: 0.6765 - val_loss: 1.5738\n",
            "Epoch 35/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 187ms/step - accuracy: 0.9527 - loss: 0.5875 - val_accuracy: 0.6814 - val_loss: 1.5535\n",
            "Epoch 36/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - accuracy: 0.9483 - loss: 0.5253 - val_accuracy: 0.6912 - val_loss: 1.5303\n",
            "Epoch 37/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 146ms/step - accuracy: 0.9719 - loss: 0.5125 - val_accuracy: 0.6863 - val_loss: 1.5069\n",
            "Epoch 38/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 144ms/step - accuracy: 0.9512 - loss: 0.5239 - val_accuracy: 0.6961 - val_loss: 1.4868\n",
            "Epoch 39/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - accuracy: 0.9763 - loss: 0.4630 - val_accuracy: 0.6863 - val_loss: 1.4720\n",
            "Epoch 40/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - accuracy: 0.9730 - loss: 0.4516 - val_accuracy: 0.6863 - val_loss: 1.4603\n",
            "Epoch 41/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 187ms/step - accuracy: 0.9714 - loss: 0.4300 - val_accuracy: 0.7010 - val_loss: 1.4464\n",
            "Epoch 42/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - accuracy: 0.9761 - loss: 0.4097 - val_accuracy: 0.6961 - val_loss: 1.4324\n",
            "Epoch 43/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 122ms/step - accuracy: 0.9785 - loss: 0.3905 - val_accuracy: 0.6912 - val_loss: 1.4181\n",
            "Epoch 44/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 123ms/step - accuracy: 0.9716 - loss: 0.3954 - val_accuracy: 0.7010 - val_loss: 1.4061\n",
            "Epoch 45/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 145ms/step - accuracy: 0.9776 - loss: 0.3747 - val_accuracy: 0.7010 - val_loss: 1.3922\n",
            "Epoch 46/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 142ms/step - accuracy: 0.9783 - loss: 0.3671 - val_accuracy: 0.6961 - val_loss: 1.3808\n",
            "Epoch 47/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - accuracy: 0.9809 - loss: 0.3446 - val_accuracy: 0.7108 - val_loss: 1.3657\n",
            "Epoch 48/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 146ms/step - accuracy: 0.9756 - loss: 0.3353 - val_accuracy: 0.7059 - val_loss: 1.3556\n",
            "Epoch 49/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 182ms/step - accuracy: 0.9826 - loss: 0.3357 - val_accuracy: 0.7108 - val_loss: 1.3468\n",
            "Epoch 50/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - accuracy: 0.9912 - loss: 0.2957 - val_accuracy: 0.7059 - val_loss: 1.3388\n",
            "ResNet50 Final Accuracy: 0.7059\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import resnet50\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# 1. Load the oxford_flowers102 Dataset\n",
        "# ---------------------------------------------------\n",
        "# Create train/validation split\n",
        "(dataset_train, dataset_test), info = tfds.load(\n",
        "    'oxford_flowers102',\n",
        "    split=['train[:80%]', 'train[80%:]'],\n",
        "    as_supervised=True,\n",
        "    with_info=True\n",
        ")\n",
        "\n",
        "# Number of classes in oxford_flowers102\n",
        "num_classes = info.features['label'].num_classes\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# 2. Preprocess Data for ResNet\n",
        "# ---------------------------------------------------\n",
        "IMG_SIZE = 224\n",
        "batch_size = 32\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "def preprocess_resnet(image, label):\n",
        "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "    image = resnet50.preprocess_input(image)  # Use resnet50's preprocess_input\n",
        "    return image, tf.one_hot(label, num_classes)\n",
        "\n",
        "# Create tf.data pipelines\n",
        "train_ds_resnet = (dataset_train\n",
        "                   .map(preprocess_resnet, num_parallel_calls=AUTOTUNE)\n",
        "                   .batch(batch_size)\n",
        "                   .prefetch(AUTOTUNE))\n",
        "\n",
        "test_ds_resnet = (dataset_test\n",
        "                  .map(preprocess_resnet, num_parallel_calls=AUTOTUNE)\n",
        "                  .batch(batch_size)\n",
        "                  .prefetch(AUTOTUNE))\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# 3. Define ResNet50 Model\n",
        "# ---------------------------------------------------\n",
        "def create_resnet(input_shape, num_classes):\n",
        "    base_model = resnet50.ResNet50(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
        "    base_model.trainable = False  # Freeze the base model\n",
        "\n",
        "    x = base_model.output\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    model = models.Model(inputs=base_model.input, outputs=outputs, name=\"ResNet50\")\n",
        "    return model\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# 4. Compile and Train the Model\n",
        "# ---------------------------------------------------\n",
        "# ResNet50 Model\n",
        "resnet_model = create_resnet((IMG_SIZE, IMG_SIZE, 3), num_classes)\n",
        "resnet_model.compile(optimizer=Adam(learning_rate=1e-4), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "print(\"\\n--- Fine-Tuning ResNet50 on oxford_flowers102 ---\")\n",
        "history_resnet = resnet_model.fit(train_ds_resnet, epochs=50, validation_data=test_ds_resnet, verbose=1)\n",
        "\n",
        "# Evaluate ResNet50\n",
        "loss_resnet, acc_resnet = resnet_model.evaluate(test_ds_resnet, verbose=0)\n",
        "print(f\"ResNet50 Final Accuracy: {acc_resnet:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}